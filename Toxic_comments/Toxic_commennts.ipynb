{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/armit/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/armit/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re  \n",
    "from tqdm import notebook \n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "comm = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of empty values</th>\n",
       "      <th>% of empty values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       # of empty values  % of empty values\n",
       "text                   0                0.0\n",
       "toxic                  0                0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for empty values\n",
    "comm\\\n",
    "    .isna()\\\n",
    "    .sum()\\\n",
    "    .to_frame()\\\n",
    "    .assign(perc = lambda row: 100 * row[0] / comm.shape[0])\\\n",
    "    .rename(columns={0: '# of empty values', 'perc': '% of empty values'})\\\n",
    "    .sort_values('% of empty values', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Duplicates ==\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "print('== Duplicates ==')\n",
    "print('')\n",
    "#test.duplicated().sum()\n",
    "\n",
    "duplicates_comm = comm[comm.duplicated() == True]\n",
    "\n",
    "print(len(duplicates_comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "comm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply appropriate data type for text colums . Necessary for the upcoming steps\n",
    "corpus = comm['text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular expression to clean text from garbage\n",
    "def clear_text(text):\n",
    "    text1 = re.sub(r'[^a-zA-Z?!)(]', ' ', text) \n",
    "    return \" \".join(text1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = clear_text(corpus[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing lemmatizier and creating a fuction for finding lemms of text\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def nltk_lemm(text):\n",
    "    for i in range(len(text)):\n",
    "        word_list = nltk.word_tokenize(text[i])\n",
    "        lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "        return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explanation Why the edits made under my username Hardcore Metallica Fan were reverted ? They weren t vandalism just closure on some GAs after I voted at New York Dolls FAC And please don t remove the template from the talk page since I m retired now'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying lemm fuction\n",
    "nltk_lemm(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a deep copy of original data frame so o be on a safe side \n",
    "comm_2 = comm.copy(deep= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding cleaned and lemmatied text to the copy \n",
    "comm_2['ready_text'] = pd.Series(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>ready_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww! He matches this background colour I m s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>And I really don t think you understand I came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                               ready_text  \n",
       "0       Explanation Why the edits made under my userna...  \n",
       "1       D aww! He matches this background colour I m s...  \n",
       "2       Hey man I m really not trying to edit war It s...  \n",
       "3       More I can t make any real suggestions on impr...  \n",
       "4       You sir are my hero Any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  And for the second time of asking when your vi...  \n",
       "159567  You should be ashamed of yourself That is a ho...  \n",
       "159568  Spitzer Umm theres no actual article for prost...  \n",
       "159569  And it looks like it was actually you who put ...  \n",
       "159570  And I really don t think you understand I came...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that operations were successful \n",
    "comm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring features and target\n",
    "\n",
    "features = comm_2.drop(['text','toxic'], axis=1)\n",
    "target = comm_2['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/armit/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#declaring words that are meaningless a.k.a stopwords from nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "# preparing TF-IDF  vector with stopwords, so that the TF-IDF  counter will not take stopwords into consideration\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting TF-IDF counter (model) with parts parts of our text\n",
    "count_tf_idf.fit(features_train['ready_text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix train: (127656, 148071)\n",
      "Matrix test: (31915, 148071)\n"
     ]
    }
   ],
   "source": [
    "# applying TF-IDF counter (model) to the data\n",
    "tf_idf_train = count_tf_idf.transform(features_train['ready_text'])\n",
    "tf_idf_test = count_tf_idf.transform(features_test['ready_text'])\n",
    "\n",
    "print(\"Matrix train:\", tf_idf_train.shape)\n",
    "print(\"Matrix test:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Summary:\n",
    "1. necessary packages imported\n",
    "2. data loaded\n",
    "3. check duplicates = 0\n",
    "4. No empty values\n",
    "5. Visial inspection - noise detected, i.e simbols that does not have meaning \n",
    "6. Noise cleaned with regular expression\n",
    "7. Lemmatization performed\n",
    "8. Applied counter TF-IDF to create feature matrix out of texts \n",
    "9. Prepared features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining list for storing results  \n",
    "models_results=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using DecisionTree model \n",
    "for depth in range(1,11):\n",
    "\n",
    "    model_tree = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model_tree.fit(tf_idf_train, target_train)\n",
    "    \n",
    "    predicted = model_tree.predict(tf_idf_test)\n",
    "    f1 = f1_score(target_test, predicted, average='micro', labels=np.unique(predicted)) \n",
    "    \n",
    "    models_results.append(['model_tree', 'Depth', depth ,f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using RandomForest model \n",
    "for estim in range(10, 111, 30):\n",
    "    for depth in range(1,11,2):\n",
    "\n",
    "        model_forest = RandomForestClassifier(n_estimators=estim, max_depth=depth, random_state=12345)\n",
    "        model_forest.fit(tf_idf_train, target_train)\n",
    "        predicted = model_forest.predict(tf_idf_test)\n",
    "        f1 = f1_score(target_test, predicted, average='micro', labels=np.unique(predicted))      \n",
    "        \n",
    "        models_results.append(['model_forest', 'Estimators/depth', str(estim)+'/'+str(depth), f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastrly using LogisticRegression model \n",
    "solver='liblinear'\n",
    "for itr in range(100,1251,250):\n",
    "    model_regres = LogisticRegression(random_state=12345,solver=solver,penalty='l1',max_iter=itr)\n",
    "    model_regres.fit(tf_idf_train, target_train)\n",
    "            \n",
    "    predicted = model_regres.predict(tf_idf_test)\n",
    "    f1 = f1_score(target_test, predicted,average='micro', labels=np.unique(predicted))    \n",
    "            \n",
    "    models_results.append(['model_regres', 'Solver/Max_iter', str(solver)+'/'+str(itr),f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "1. Trained 3 models with different hyperparams\n",
    "2. Calculated f1,with option ='micro', i.e without makeing favour to target (0/1)\n",
    "3. All performed results saved in table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating final dataframe with results \n",
    "column_names = ['model', 'hyper_param', 'hyper_param_value', 'f1_score']\n",
    "\n",
    "df_results = pd.DataFrame(models_results, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hyper_param</th>\n",
       "      <th>hyper_param_value</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>2</td>\n",
       "      <td>0.920915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>6</td>\n",
       "      <td>0.932101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>8</td>\n",
       "      <td>0.935610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>9</td>\n",
       "      <td>0.937240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>10</td>\n",
       "      <td>0.938587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>10/1</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>10/3</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>10/5</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>10/7</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>10/9</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>40/1</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>40/3</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>40/5</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>40/7</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>40/9</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>70/1</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>70/3</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>70/5</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>70/7</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>70/9</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>100/1</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>100/3</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>100/5</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>100/7</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>100/9</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model       hyper_param hyper_param_value  f1_score\n",
       "0     model_tree             Depth                 1  0.913928\n",
       "1     model_tree             Depth                 2  0.920915\n",
       "2     model_tree             Depth                 3  0.924644\n",
       "3     model_tree             Depth                 4  0.927620\n",
       "4     model_tree             Depth                 5  0.930378\n",
       "5     model_tree             Depth                 6  0.932101\n",
       "6     model_tree             Depth                 7  0.934294\n",
       "7     model_tree             Depth                 8  0.935610\n",
       "8     model_tree             Depth                 9  0.937240\n",
       "9     model_tree             Depth                10  0.938587\n",
       "10  model_forest  Estimators/depth              10/1  0.946456\n",
       "11  model_forest  Estimators/depth              10/3  0.946456\n",
       "12  model_forest  Estimators/depth              10/5  0.946456\n",
       "13  model_forest  Estimators/depth              10/7  0.946456\n",
       "14  model_forest  Estimators/depth              10/9  0.946456\n",
       "15  model_forest  Estimators/depth              40/1  0.946456\n",
       "16  model_forest  Estimators/depth              40/3  0.946456\n",
       "17  model_forest  Estimators/depth              40/5  0.946456\n",
       "18  model_forest  Estimators/depth              40/7  0.946456\n",
       "19  model_forest  Estimators/depth              40/9  0.946456\n",
       "20  model_forest  Estimators/depth              70/1  0.946456\n",
       "21  model_forest  Estimators/depth              70/3  0.946456\n",
       "22  model_forest  Estimators/depth              70/5  0.946456\n",
       "23  model_forest  Estimators/depth              70/7  0.946456\n",
       "24  model_forest  Estimators/depth              70/9  0.946456\n",
       "25  model_forest  Estimators/depth             100/1  0.946456\n",
       "26  model_forest  Estimators/depth             100/3  0.946456\n",
       "27  model_forest  Estimators/depth             100/5  0.946456\n",
       "28  model_forest  Estimators/depth             100/7  0.946456\n",
       "29  model_forest  Estimators/depth             100/9  0.946456"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hyper_param</th>\n",
       "      <th>hyper_param_value</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>40/1</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>40/3</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>model_forest</td>\n",
       "      <td>Estimators/depth</td>\n",
       "      <td>100/7</td>\n",
       "      <td>0.946456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model       hyper_param hyper_param_value  f1_score\n",
       "15  model_forest  Estimators/depth              40/1  0.946456\n",
       "16  model_forest  Estimators/depth              40/3  0.946456\n",
       "28  model_forest  Estimators/depth             100/7  0.946456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Top 3 results\n",
    "display(df_results.sort_values(by='f1_score', ascending=False).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hyper_param</th>\n",
       "      <th>hyper_param_value</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>2</td>\n",
       "      <td>0.920915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>model_tree</td>\n",
       "      <td>Depth</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model hyper_param hyper_param_value  f1_score\n",
       "0  model_tree       Depth                 1  0.913928\n",
       "1  model_tree       Depth                 2  0.920915\n",
       "2  model_tree       Depth                 3  0.924644"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3 outsiders\n",
    "display(df_results.sort_values(by='f1_score', ascending=True).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final summary\n",
    "\n",
    "1. Applied 3 models: Decesion treee, Random Forest, Logistic Regression\n",
    "2. All got metric higher than trashhold \n",
    "4. Top model: Logistic Regression с f1= 0.960457\n",
    "5. Worst model: Decesion treee с f1 = 0.913928\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note TBD:\n",
    "Research if feature \"comment length\" can improve metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are experimental cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro:  0.8566845045529252\n",
      "f1 micro:  0.955851480495065\n",
      "f1 weighted:  0.9516641149672989\n",
      "f1 None:  [0.97589929 0.73746972]\n"
     ]
    }
   ],
   "source": [
    "print('f1 macro: ', f1_score(target_test, predict, average='macro'))\n",
    "\n",
    "print('f1 micro: ', f1_score(target_test, predict, average='micro'))\n",
    "\n",
    "print('f1 weighted: ', f1_score(target_test, predict, average='weighted'))\n",
    "\n",
    "print('f1 None: ', f1_score(target_test, predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " elif solver=='lbfgs':\n",
    "        print('---------------')\n",
    "        for itr in range(100,1251,250):\n",
    "            model_regres = LogisticRegression(random_state=12345,solver=solver,penalty='l2',max_iter=itr)\n",
    "            model_regres.fit(tf_idf_train, target_train)\n",
    "            \n",
    "            predicted = model_regres.predict(tf_idf_test)\n",
    "            f1 = f1_score(target_test, predicted,average='micro', labels=np.unique(predicted))      \n",
    "            \n",
    "            models_results.append(['model_regres', 'Solver/Max_iter', str(solver)+'/'+str(itr),f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    m = Mystem()\n",
    "    lemmas = m.lemmatize(text)\n",
    "    return ''.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0).fit(tf_idf_train, target_train)\n",
    "predict = model.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_list=['liblinear','lbfgs']\n",
    "for solver in sl_list:\n",
    "    if solver=='liblinear':\n",
    "        for itr in range(100,1251,250):\n",
    "            model_regres = LogisticRegression(random_state=12345,solver='liblinear',penalty='l1',max_iter=itr)\n",
    "            model_regres.fit(tf_idf_train, target_train)\n",
    "            \n",
    "            predicted = model_regres.predict(tf_idf_test)\n",
    "            f1 = f1_score(target_test, predicted,average='micro', labels=np.unique(predicted))    \n",
    "            \n",
    "            models_results.append(['model_regres', 'Solver/Max_iter', str(solver)+'/'+str(itr),f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lemm = lemmatize(corpus[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    comm.loc[i:'text_lemm'] = lemmatize(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5acdccb14a6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ready_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#corpus = comm['text'].values.astype('U')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_train' is not defined"
     ]
    }
   ],
   "source": [
    "#train_values = features_train['ready_text'].values.astype('U')\n",
    "#corpus = comm['text'].values.astype('U')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
